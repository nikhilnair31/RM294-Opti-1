{"cells":[{"cell_type":"code","execution_count":1,"id":"a0563b02","metadata":{"id":"a0563b02"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.linear_model import LinearRegression\n","import seaborn as sns   # Why sns?  It's a reference to The West Wing\n","import matplotlib.pyplot as plt  # seaborn is based on matplotlib\n","sns.set(color_codes=True) # adds a nice background to the graphs\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"id":"0774e40d","metadata":{"id":"0774e40d"},"outputs":[{"name":"stdout","output_type":"stream","text":["100\n"]}],"source":["df = pd.read_csv('topic3_regression_data.csv')\n","ndata = df.shape[0]\n","x1 = df['x1']\n","x2 = df['x2']\n","y = df['y']\n","print(ndata)"]},{"cell_type":"code","execution_count":3,"id":"70b14d60","metadata":{"id":"70b14d60"},"outputs":[{"name":"stdout","output_type":"stream","text":["[ 1.15736763 -0.48388328  0.85474407]\n"]}],"source":["reg = LinearRegression().fit(df[['x1','x2']], df['y'])\n","beta_ols = np.append(reg.intercept_,reg.coef_)\n","print(beta_ols)"]},{"cell_type":"markdown","id":"6729dbe2","metadata":{"id":"6729dbe2"},"source":["# how to calculate the gradient\n","\n","\n","$ obj = \\frac{1}{n} \\sum_{i=1}^n (\\hat{y}_i - y_i)^2 $\n","\n","$ \\frac{\\partial obj}{\\partial \\beta_0} = \\frac{1}{n} \\sum_{i=1}^n 2(\\hat{y}_i - y_i)$\n","\n","$ \\frac{\\partial obj}{\\partial \\beta_1} = \\frac{1}{n} \\sum_{i=1}^n 2(\\hat{y}_i - y_i)x_{1i}$\n","\n","$ \\frac{\\partial obj}{\\partial \\beta_2} = \\frac{1}{n} \\sum_{i=1}^n 2(\\hat{y}_i - y_i)x_{2i}$\n","\n","$ \\nabla obj = \\left( \\frac{\\partial obj}{\\partial \\beta_0}, \\frac{\\partial obj}{\\partial \\beta_1}, \\frac{\\partial obj}{\\partial \\beta_2}\\right) $"]},{"cell_type":"markdown","id":"iZAwUl9GGu9k","metadata":{"id":"iZAwUl9GGu9k"},"source":["# SGD with Momentum"]},{"cell_type":"code","execution_count":4,"id":"tcByqn96HDet","metadata":{"id":"tcByqn96HDet"},"outputs":[],"source":["learnRate = 1e-3\n","epochs = 200\n","batches = 10\n","dat_per_bat = ndata//batches\n","theta1 = 0.9"]},{"cell_type":"code","execution_count":5,"id":"7L1s8vvIGuEY","metadata":{"id":"7L1s8vvIGuEY"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.35044887441848593\n","[ 1.1422902  -0.4851039   0.84476918]\n","[ 1.15736763 -0.48388328  0.85474407]\n"]}],"source":["# SGD with momentum\n","\n","SGDMOMError = np.zeros(epochs)\n","beta = np.zeros(3)\n","k = 1\n","m = np.zeros(3)\n","for ep in range(epochs):\n","    shuf = np.random.choice(range(ndata),size=ndata,replace=False)\n","    for bat in range(batches):\n","        this_bat = shuf[(bat*dat_per_bat):((bat+1)*dat_per_bat)]\n","        yhat = beta[0] + beta[1]*x1[this_bat] + beta[2]*x2[this_bat]\n","\n","        grad0 = 2.0*np.mean(yhat-y[this_bat])\n","        grad1 = 2.0*np.mean((yhat-y[this_bat])*x1[this_bat])\n","        grad2 = 2.0*np.mean((yhat-y[this_bat])*x2[this_bat])\n","        grad = np.array([grad0,grad1,grad2])\n","\n","        m = theta1*m + (1-theta1)*grad\n","        mhat = m/(1-theta1**k)\n","\n","        beta -= learnRate*mhat\n","        k += 1\n","\n","\n","    yhat = beta[0] + beta[1]*x1 + beta[2]*x2\n","    SGDMOMError[ep] = np.mean((yhat-y)**2)\n","\n","print(SGDMOMError[epochs-1])\n","print(beta)\n","print(beta_ols)"]},{"cell_type":"markdown","id":"SiH_4whUJEPG","metadata":{"id":"SiH_4whUJEPG"},"source":["# ADAM"]},{"cell_type":"code","execution_count":6,"id":"4orYrs1QJHJY","metadata":{"id":"4orYrs1QJHJY"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.3560130485551429\n","[ 1.08463773 -0.49107559  0.83351088]\n","[ 1.15736763 -0.48388328  0.85474407]\n"]}],"source":["# adam\n","\n","theta2 = 0.999\n","e=1e-12\n","\n","\n","ADAMError = np.zeros(epochs)\n","beta = np.zeros(3)\n","k = 1\n","m = np.zeros(3)\n","v = np.zeros(3)\n","for ep in range(epochs):\n","    shuf = np.random.choice(range(ndata),size=ndata,replace=False)\n","    for bat in range(batches):\n","        this_bat = shuf[(bat*dat_per_bat):((bat+1)*dat_per_bat)]\n","        yhat = beta[0] + beta[1]*x1[this_bat] + beta[2]*x2[this_bat]\n","\n","        grad0 = 2.0*np.mean(yhat-y[this_bat])\n","        grad1 = 2.0*np.mean((yhat-y[this_bat])*x1[this_bat])\n","        grad2 = 2.0*np.mean((yhat-y[this_bat])*x2[this_bat])\n","        grad = np.array([grad0,grad1,grad2])\n","\n","        m = theta1*m + (1-theta1)*grad\n","        mhat = m/(1-theta1**k)\n","\n","        v = theta2*v + (1-theta2)*(grad**2)\n","        vhat = v/(1-theta2**k)\n","\n","        beta -= learnRate*mhat/(np.sqrt(vhat)+e)\n","        k += 1\n","\n","\n","    yhat = beta[0] + beta[1]*x1 + beta[2]*x2\n","    ADAMError[ep] = np.mean((yhat-y)**2)\n","\n","print(ADAMError[ep])\n","print(beta)\n","print(beta_ols)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":5}
